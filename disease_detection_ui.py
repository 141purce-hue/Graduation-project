import sys
import cv2
import numpy as np
import subprocess
from pathlib import Path
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout,
                             QHBoxLayout, QPushButton, QLabel, QFileDialog,
                             QRadioButton, QButtonGroup, QFrame, QTextEdit,
                             QProgressBar, QGroupBox, QMessageBox)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QPixmap, QImage, QFont, QPalette, QColor
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False

from config import *


def check_wifi_connection(target_ssid="HW_ESP32S3CAM"):
    """
    æ£€æŸ¥å½“å‰ WiFi è¿æ¥æ˜¯å¦ä¸ºæŒ‡å®šçš„ SSID

    Args:
        target_ssid: ç›®æ ‡ WiFi åç§°

    Returns:
        tuple: (æ˜¯å¦è¿æ¥, å½“å‰SSID, é”™è¯¯ä¿¡æ¯)
    """
    try:
        # Windows ç³»ç»Ÿä½¿ç”¨ netsh å‘½ä»¤
        result = subprocess.run(
            ['netsh', 'wlan', 'show', 'interfaces'],
            capture_output=True,
            text=False  # è·å–å­—èŠ‚æ•°æ®ï¼Œé¿å…ç¼–ç é—®é¢˜
        )

        if result.returncode == 0:
            # å°è¯•å¤šç§ç¼–ç æ–¹å¼è§£ç ï¼Œé¿å…ç¼–ç é”™è¯¯
            output = None
            for encoding in ['gbk', 'utf-8', 'cp936', 'gb2312']:
                try:
                    output = result.stdout.decode(encoding, errors='ignore')
                    break
                except:
                    continue

            if output is None:
                return False, "", "æ— æ³•è§£ç  WiFi ä¿¡æ¯"

            # æŸ¥æ‰¾ SSID è¡Œ
            for line in output.split('\n'):
                if 'SSID' in line and ':' in line:
                    # æå– SSID åç§°
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        current_ssid = parts[1].strip()
                        # è·³è¿‡ BSSID è¡Œ
                        if 'BSSID' not in line:
                            is_connected = (current_ssid == target_ssid)
                            return is_connected, current_ssid, None

            return False, "æœªè¿æ¥åˆ°ä»»ä½• WiFi", None
        else:
            return False, "", "æ— æ³•è·å– WiFi ä¿¡æ¯"

    except Exception as e:
        return False, "", f"æ£€æŸ¥ WiFi è¿æ¥æ—¶å‡ºé”™: {str(e)}"


class ONNXModel:
    """ONNXæ¨¡å‹æ¨ç†ç±»"""
    def __init__(self, model_path, class_names):
        """
        åˆå§‹åŒ–ONNXæ¨¡å‹

        Args:
            model_path: ONNXæ¨¡å‹æ–‡ä»¶è·¯å¾„
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
        """
        self.model_path = model_path
        self.class_names = class_names
        self.session = None
        self.input_name = None
        self.output_names = None
        self.input_shape = None

        # åŠ è½½æ¨¡å‹
        self._load_model()

    def _load_model(self):
        """åŠ è½½ONNXæ¨¡å‹"""
        # åˆ›å»ºæ¨ç†ä¼šè¯
        providers = ['CPUExecutionProvider']

        # å¦‚æœæœ‰GPUï¼Œä¼˜å…ˆä½¿ç”¨CUDA
        if 'CUDAExecutionProvider' in ort.get_available_providers():
            providers.insert(0, 'CUDAExecutionProvider')

        self.session = ort.InferenceSession(self.model_path, providers=providers)

        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_name = self.session.get_inputs()[0].name
        self.output_names = [output.name for output in self.session.get_outputs()]
        self.input_shape = self.session.get_inputs()[0].shape

        # è·å–è¾“å…¥å°ºå¯¸ï¼ˆé€šå¸¸æ˜¯ [batch, channels, height, width]ï¼‰
        if len(self.input_shape) == 4:
            self.img_size = self.input_shape[2]  # å‡è®¾é«˜å®½ç›¸åŒ
        else:
            self.img_size = 640  # é»˜è®¤å€¼

    def preprocess(self, image):
        """
        é¢„å¤„ç†å›¾åƒ

        Args:
            image: OpenCVæ ¼å¼çš„å›¾åƒ (BGR)

        Returns:
            preprocessed: é¢„å¤„ç†åçš„å›¾åƒ
            ratio: ç¼©æ”¾æ¯”ä¾‹
            (dw, dh): å¡«å……å¤§å°
        """
        # è·å–åŸå§‹å›¾åƒå°ºå¯¸
        img_h, img_w = image.shape[:2]

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        ratio = min(self.img_size / img_h, self.img_size / img_w)
        new_h, new_w = int(img_h * ratio), int(img_w * ratio)

        # ç¼©æ”¾å›¾åƒ
        resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        # åˆ›å»ºå¡«å……åçš„å›¾åƒ
        dh, dw = (self.img_size - new_h) // 2, (self.img_size - new_w) // 2
        padded = np.full((self.img_size, self.img_size, 3), 114, dtype=np.uint8)
        padded[dh:dh+new_h, dw:dw+new_w] = resized

        # è½¬æ¢ä¸ºRGBå¹¶å½’ä¸€åŒ–
        padded = cv2.cvtColor(padded, cv2.COLOR_BGR2RGB)
        padded = padded.transpose(2, 0, 1).astype(np.float32) / 255.0

        # æ·»åŠ batchç»´åº¦
        padded = np.expand_dims(padded, axis=0)

        return padded, ratio, (dw, dh)

    def postprocess(self, outputs, ratio, pad, conf_threshold=0.5, iou_threshold=0.45):
        """
        åå¤„ç†æ¨¡å‹è¾“å‡º

        Args:
            outputs: æ¨¡å‹è¾“å‡º
            ratio: ç¼©æ”¾æ¯”ä¾‹
            pad: å¡«å……å¤§å°
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: NMSçš„IOUé˜ˆå€¼

        Returns:
            boxes: æ£€æµ‹æ¡† [x1, y1, x2, y2, conf, cls]
        """
        # è·å–è¾“å‡º
        predictions = outputs[0]

        # å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
        # YOLOv8 ONNX è¾“å‡ºæ ¼å¼: [batch, 4+num_classes, num_boxes]
        # éœ€è¦è½¬ç½®ä¸º: [batch, num_boxes, 4+num_classes]
        if len(predictions.shape) == 3:
            # å¦‚æœæ˜¯ [1, 8, 2100] æ ¼å¼ï¼Œè½¬ç½®ä¸º [1, 2100, 8]
            if predictions.shape[1] < predictions.shape[2]:
                predictions = predictions.transpose(0, 2, 1)

            # ç§»é™¤batchç»´åº¦
            predictions = predictions[0]  # ç°åœ¨æ˜¯ [num_boxes, 4+num_classes]

        # åˆ†ç¦»åæ ‡å’Œç±»åˆ«æ¦‚ç‡
        # predictions ç°åœ¨åº”è¯¥æ˜¯ [num_boxes, 4+num_classes]
        # å‰4åˆ—æ˜¯è¾¹ç•Œæ¡†åæ ‡ [x, y, w, h]
        # åé¢çš„åˆ—æ˜¯ç±»åˆ«æ¦‚ç‡
        boxes = predictions[:, :4]  # [num_boxes, 4]
        class_scores = predictions[:, 4:]  # [num_boxes, num_classes]

        # è·å–æ¯ä¸ªæ¡†çš„æœ€å¤§ç±»åˆ«æ¦‚ç‡å’Œå¯¹åº”çš„ç±»åˆ«ID
        class_ids = np.argmax(class_scores, axis=1)
        confidences = np.max(class_scores, axis=1)

        # è¿‡æ»¤ä½ç½®ä¿¡åº¦çš„æ¡†
        mask = confidences > conf_threshold
        boxes = boxes[mask]
        confidences = confidences[mask]
        class_ids = class_ids[mask]

        if len(boxes) == 0:
            return np.array([])

        # è½¬æ¢åæ ‡æ ¼å¼ (ä¸­å¿ƒç‚¹+å®½é«˜ -> å·¦ä¸Šè§’+å³ä¸‹è§’)
        x_center, y_center, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
        x1 = x_center - w / 2
        y1 = y_center - h / 2
        x2 = x_center + w / 2
        y2 = y_center + h / 2

        # è¿˜åŸåˆ°åŸå§‹å›¾åƒåæ ‡
        dw, dh = pad
        x1 = (x1 - dw) / ratio
        y1 = (y1 - dh) / ratio
        x2 = (x2 - dw) / ratio
        y2 = (y2 - dh) / ratio

        # NMS
        indices = cv2.dnn.NMSBoxes(
            boxes.tolist(),
            confidences.tolist(),
            conf_threshold,
            iou_threshold
        )

        if len(indices) == 0:
            return np.array([])

        # ç»„åˆç»“æœ
        results = []
        for i in indices.flatten():
            results.append([x1[i], y1[i], x2[i], y2[i], confidences[i], class_ids[i]])

        return np.array(results)

    def predict(self, image, conf_threshold=0.5):
        """
        é¢„æµ‹å›¾åƒ

        Args:
            image: OpenCVæ ¼å¼çš„å›¾åƒ
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            boxes: æ£€æµ‹ç»“æœ [x1, y1, x2, y2, conf, cls]
        """
        # é¢„å¤„ç†
        input_data, ratio, pad = self.preprocess(image)

        # æ¨ç†
        outputs = self.session.run(self.output_names, {self.input_name: input_data})

        # åå¤„ç†
        boxes = self.postprocess(outputs, ratio, pad, conf_threshold)

        return boxes

    def draw_boxes(self, image, boxes):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†

        Args:
            image: åŸå§‹å›¾åƒ
            boxes: æ£€æµ‹æ¡†

        Returns:
            annotated_image: æ ‡æ³¨åçš„å›¾åƒ
        """
        annotated = image.copy()

        # å®šä¹‰é¢œè‰²
        colors = {
            0: (39, 174, 96),   # ç»¿è‰² - Healthy Leaf
            1: (230, 126, 34),  # æ©™è‰² - Leaf Mold
            2: (231, 76, 60),   # çº¢è‰² - Septoria leaf spot
            3: (155, 89, 182)   # ç´«è‰² - Tomato leaf bacterial spot
        }

        for box in boxes:
            x1, y1, x2, y2, conf, cls = box
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            cls = int(cls)

            # è·å–é¢œè‰²
            color = colors.get(cls, (52, 152, 219))  # é»˜è®¤è“è‰²

            # ç»˜åˆ¶çŸ©å½¢æ¡†
            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)

            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            label = f"{self.class_names[cls]}: {conf:.2%}"

            # è®¡ç®—æ–‡æœ¬å¤§å°
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )

            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(
                annotated,
                (x1, y1 - text_height - baseline - 5),
                (x1 + text_width, y1),
                color,
                -1
            )

            # ç»˜åˆ¶æ–‡æœ¬
            cv2.putText(
                annotated,
                label,
                (x1, y1 - baseline - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2
            )

        return annotated


class VideoThread(QThread):
    """è§†é¢‘å¤„ç†çº¿ç¨‹"""
    change_pixmap_signal = pyqtSignal(np.ndarray)
    result_signal = pyqtSignal(str, float)
    finished_signal = pyqtSignal()

    def __init__(self, video_path, model, is_onnx=False):
        super().__init__()
        self.video_path = video_path
        self.model = model
        self.is_onnx = is_onnx
        self.running = True

    def run(self):
        cap = cv2.VideoCapture(self.video_path)

        # è·å–è§†é¢‘çš„å¸§ç‡ï¼Œç”¨äºæ­£å¸¸é€Ÿåº¦æ’­æ”¾
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps <= 0:
            fps = 30  # é»˜è®¤30fps
        frame_delay = int(1000 / fps)  # è®¡ç®—æ¯å¸§å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰

        while self.running and cap.isOpened():
            ret, frame = cap.read()
            if ret:
                if self.is_onnx:
                    # ONNXæ¨¡å‹æ¨ç†
                    boxes = self.model.predict(frame, conf_threshold=CONFIDENCE_THRESHOLD)

                    # ç»˜åˆ¶ç»“æœ
                    annotated_frame = self.model.draw_boxes(frame, boxes)

                    # å‘é€æ£€æµ‹ç»“æœ
                    for box in boxes:
                        cls_id = int(box[5])
                        conf = float(box[4])
                        class_name = self.model.class_names[cls_id]
                        self.result_signal.emit(class_name, conf)
                else:
                    # Ultralytics YOLOæ¨ç†
                    results = self.model.predict(source=frame, conf=CONFIDENCE_THRESHOLD, verbose=False)

                    # ç»˜åˆ¶ç»“æœ
                    annotated_frame = results[0].plot()

                    # è·å–é¢„æµ‹ç»“æœ
                    if len(results[0].boxes) > 0:
                        for box in results[0].boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            class_name = results[0].names[cls_id]
                            self.result_signal.emit(class_name, conf)

                self.change_pixmap_signal.emit(annotated_frame)
                self.msleep(frame_delay)  # æ ¹æ®è§†é¢‘å¸§ç‡æ§åˆ¶æ’­æ”¾é€Ÿåº¦
            else:
                break

        cap.release()
        self.finished_signal.emit()

    def stop(self):
        self.running = False
        self.wait()


class CameraThread(QThread):
    """ESP32S3CAM æ‘„åƒå¤´å¤„ç†çº¿ç¨‹"""
    change_pixmap_signal = pyqtSignal(np.ndarray)
    result_signal = pyqtSignal(str, float)
    error_signal = pyqtSignal(str)

    def __init__(self, camera_url, model, is_onnx=False):
        super().__init__()
        self.camera_url = camera_url
        self.model = model
        self.is_onnx = is_onnx
        self.running = True

    def run(self):
        """è¿è¡Œæ‘„åƒå¤´æµè¯†åˆ«"""
        cap = None
        try:
            # è¿æ¥æ‘„åƒå¤´æµï¼ˆè®¾ç½®è¶…æ—¶ï¼‰
            import os
            os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'timeout;5000000'  # 5ç§’è¶…æ—¶

            cap = cv2.VideoCapture(self.camera_url, cv2.CAP_FFMPEG)

            # ç­‰å¾…è¿æ¥å»ºç«‹ï¼ˆæœ€å¤šç­‰å¾…5ç§’ï¼‰
            max_retries = 10
            retry_count = 0
            while retry_count < max_retries and not cap.isOpened() and self.running:
                self.msleep(500)
                retry_count += 1

            if not cap.isOpened():
                self.error_signal.emit("æ— æ³•è¿æ¥åˆ°æ‘„åƒå¤´æµ\n\nå¯èƒ½åŸå› ï¼š\n1. WiFi æœªè¿æ¥åˆ°æ‘„åƒå¤´\n2. æ‘„åƒå¤´æœªå¼€å¯\n3. æ‘„åƒå¤´åœ°å€ä¸æ­£ç¡®\n4. ç½‘ç»œè¿æ¥é—®é¢˜")
                return

            # ä¼˜åŒ–è®¾ç½®ä»¥å‡å°‘å»¶è¿Ÿ
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # æœ€å°ç¼“å†²åŒºï¼Œå‡å°‘å»¶è¿Ÿ
            cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, 5000)
            cap.set(cv2.CAP_PROP_READ_TIMEOUT_MSEC, 5000)

            # å°è¯•è®¾ç½®æ›´ä½çš„åˆ†è¾¨ç‡ä»¥æé«˜å¸§ç‡ï¼ˆå¦‚æœæ‘„åƒå¤´æ”¯æŒï¼‰
            # cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            # cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

            frame_count = 0
            consecutive_failures = 0
            max_consecutive_failures = 10

            # è·³å¸§æ£€æµ‹ï¼šæ¯Nå¸§æ£€æµ‹ä¸€æ¬¡ï¼Œå…¶ä»–å¸§ç›´æ¥æ˜¾ç¤º
            detect_interval = CAMERA_DETECT_INTERVAL  # ä»é…ç½®æ–‡ä»¶è¯»å–
            last_annotated_frame = None
            last_boxes = []

            while self.running:
                ret, frame = cap.read()
                if ret:
                    frame_count += 1
                    consecutive_failures = 0

                    # è·³å¸§æ£€æµ‹ç­–ç•¥ï¼šåªåœ¨ç‰¹å®šå¸§è¿›è¡Œæ£€æµ‹
                    should_detect = (frame_count % detect_interval == 0)

                    if should_detect:
                        # è¿›è¡Œç›®æ ‡æ£€æµ‹
                        if self.is_onnx:
                            # ONNXæ¨¡å‹æ¨ç†
                            boxes = self.model.predict(frame, conf_threshold=CONFIDENCE_THRESHOLD)
                            annotated_frame = self.model.draw_boxes(frame.copy(), boxes)
                            last_boxes = boxes

                            # å‘é€æ£€æµ‹ç»“æœï¼ˆåªåœ¨æ£€æµ‹æ—¶å‘é€ï¼‰
                            for box in boxes:
                                cls_id = int(box[5])
                                conf = float(box[4])
                                class_name = self.model.class_names[cls_id]
                                self.result_signal.emit(class_name, conf)
                        else:
                            # YOLOæ¨¡å‹æ¨ç†
                            results = self.model(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)
                            annotated_frame = results[0].plot()

                            # å‘é€æ£€æµ‹ç»“æœ
                            for box in results[0].boxes:
                                cls_id = int(box.cls[0])
                                conf = float(box.conf[0])
                                class_name = results[0].names[cls_id]
                                self.result_signal.emit(class_name, conf)

                        last_annotated_frame = annotated_frame
                    else:
                        # ä¸æ£€æµ‹çš„å¸§ï¼šä½¿ç”¨ä¸Šä¸€æ¬¡çš„æ£€æµ‹ç»“æœç»˜åˆ¶
                        if last_annotated_frame is not None and self.is_onnx and len(last_boxes) > 0:
                            # åœ¨å½“å‰å¸§ä¸Šç»˜åˆ¶ä¸Šä¸€æ¬¡çš„æ£€æµ‹æ¡†
                            annotated_frame = self.model.draw_boxes(frame.copy(), last_boxes)
                        elif last_annotated_frame is not None:
                            # å¦‚æœæœ‰ä¸Šä¸€å¸§çš„ç»“æœï¼Œç›´æ¥ä½¿ç”¨å½“å‰å¸§ï¼ˆä¸ç»˜åˆ¶æ¡†ï¼‰
                            annotated_frame = frame
                        else:
                            # ç¬¬ä¸€å¸§ï¼Œç›´æ¥æ˜¾ç¤ºåŸå§‹ç”»é¢
                            annotated_frame = frame

                    # å‘é€ç”»é¢æ›´æ–°
                    self.change_pixmap_signal.emit(annotated_frame)

                    # ä½¿ç”¨é…ç½®çš„å»¶è¿Ÿæ—¶é—´
                    self.msleep(CAMERA_FRAME_DELAY)

                else:
                    # è¯»å–å¤±è´¥
                    consecutive_failures += 1

                    if consecutive_failures >= max_consecutive_failures:
                        self.error_signal.emit("æ‘„åƒå¤´è¿æ¥ä¸ç¨³å®šï¼Œå·²æ–­å¼€\n\nè¯·æ£€æŸ¥ï¼š\n1. WiFi ä¿¡å·å¼ºåº¦\n2. æ‘„åƒå¤´æ˜¯å¦æ­£å¸¸å·¥ä½œ")
                        break

                    # çŸ­æš‚ç­‰å¾…åç»§ç»­å°è¯•
                    self.msleep(100)

        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            self.error_signal.emit(f"æ‘„åƒå¤´è¯†åˆ«é”™è¯¯: {str(e)}\n\nè¯¦ç»†ä¿¡æ¯:\n{error_detail}")
        finally:
            # ç¡®ä¿é‡Šæ”¾æ‘„åƒå¤´èµ„æº
            if cap is not None:
                cap.release()

    def stop(self):
        """åœæ­¢æ‘„åƒå¤´è¯†åˆ«"""
        self.running = False
        # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œæœ€å¤šç­‰å¾…3ç§’
        if not self.wait(3000):
            # å¦‚æœ3ç§’åè¿˜æ²¡ç»“æŸï¼Œå¼ºåˆ¶ç»ˆæ­¢
            self.terminate()
            self.wait()


class DiseaseDetectionUI(QMainWindow):
    def __init__(self):
        super().__init__()
        self.model = None
        self.video_thread = None
        self.camera_thread = None
        self.class_names = CLASS_NAMES
        self.is_onnx = False  # æ ‡è®°æ˜¯å¦ä½¿ç”¨ONNXæ¨¡å‹
        self.camera_url = "http://192.168.5.1:81/stream"  # ESP32S3CAM æ‘„åƒå¤´åœ°å€
        self.camera_wifi_ssid = "HW_ESP32S3CAM"  # æ‘„åƒå¤´ WiFi åç§°
        self.init_ui()
        self.load_model()

    def init_ui(self):
        """åˆå§‹åŒ–UIç•Œé¢"""
        self.setWindowTitle(WINDOW_TITLE)
        self.setGeometry(100, 100, WINDOW_WIDTH, WINDOW_HEIGHT)

        # è®¾ç½®æ•´ä½“æ ·å¼
        self.setStyleSheet("""
            QMainWindow {
                background-color: #f0f4f8;
            }
            QLabel {
                color: #2c3e50;
            }
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 12px 24px;
                border-radius: 8px;
                font-size: 14px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #2980b9;
            }
            QPushButton:pressed {
                background-color: #21618c;
            }
            QPushButton:disabled {
                background-color: #bdc3c7;
            }
            QRadioButton {
                color: #2c3e50;
                font-size: 13px;
                spacing: 8px;
            }
            QRadioButton::indicator {
                width: 18px;
                height: 18px;
            }
            QGroupBox {
                font-weight: bold;
                font-size: 14px;
                color: #2c3e50;
                border: 2px solid #bdc3c7;
                border-radius: 8px;
                margin-top: 12px;
                padding-top: 12px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 15px;
                padding: 0 5px;
            }
            QTextEdit {
                background-color: white;
                border: 2px solid #bdc3c7;
                border-radius: 8px;
                padding: 8px;
                font-size: 12px;
            }
        """)

        # ä¸»çª—å£éƒ¨ä»¶
        main_widget = QWidget()
        self.setCentralWidget(main_widget)
        main_layout = QHBoxLayout(main_widget)
        main_layout.setSpacing(20)
        main_layout.setContentsMargins(20, 20, 20, 20)

        # å·¦ä¾§æ§åˆ¶é¢æ¿
        left_panel = self.create_left_panel()
        main_layout.addWidget(left_panel, 1)

        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        right_panel = self.create_right_panel()
        main_layout.addWidget(right_panel, 2)

    def create_left_panel(self):
        """åˆ›å»ºå·¦ä¾§æ§åˆ¶é¢æ¿"""
        panel = QFrame()
        panel.setStyleSheet("""
            QFrame {
                background-color: white;
                border-radius: 12px;
                padding: 15px;
            }
        """)
        layout = QVBoxLayout(panel)
        layout.setSpacing(20)

        # æ ‡é¢˜
        title = QLabel("ğŸ¯ æ§åˆ¶é¢æ¿")
        title.setFont(QFont("Arial", 18, QFont.Bold))
        title.setStyleSheet("color: #2c3e50; padding: 10px;")
        layout.addWidget(title)

        # è¯†åˆ«æ¨¡å¼é€‰æ‹©
        mode_group = QGroupBox("è¯†åˆ«æ¨¡å¼")
        mode_layout = QVBoxLayout()

        self.mode_group = QButtonGroup()
        self.image_radio = QRadioButton("ğŸ“· å›¾ç‰‡è¯†åˆ«")
        self.video_radio = QRadioButton("ğŸ¥ è§†é¢‘è¯†åˆ«")
        self.camera_radio = QRadioButton("ğŸ“¹ æ‘„åƒå¤´è¯†åˆ« (ESP32S3CAM)")
        self.image_radio.setChecked(True)

        self.mode_group.addButton(self.image_radio, 1)
        self.mode_group.addButton(self.video_radio, 2)
        self.mode_group.addButton(self.camera_radio, 3)

        mode_layout.addWidget(self.image_radio)
        mode_layout.addWidget(self.video_radio)
        mode_layout.addWidget(self.camera_radio)
        mode_group.setLayout(mode_layout)
        layout.addWidget(mode_group)

        # è¿æ¥æ¨¡å¼åˆ‡æ¢ä¿¡å·
        self.mode_group.buttonClicked.connect(self.on_mode_changed)

        # æ–‡ä»¶é€‰æ‹©æŒ‰é’®
        self.select_btn = QPushButton("ğŸ“ é€‰æ‹©æ–‡ä»¶")
        self.select_btn.clicked.connect(self.select_file)
        self.select_btn.setStyleSheet("""
            QPushButton {
                background-color: #27ae60;
                font-size: 15px;
                padding: 15px;
            }
            QPushButton:hover {
                background-color: #229954;
            }
        """)
        layout.addWidget(self.select_btn)

        # å¼€å§‹è¯†åˆ«æŒ‰é’®
        self.detect_btn = QPushButton("ğŸ” å¼€å§‹è¯†åˆ«")
        self.detect_btn.clicked.connect(self.start_detection)
        self.detect_btn.setEnabled(False)
        self.detect_btn.setStyleSheet("""
            QPushButton {
                background-color: #e74c3c;
                font-size: 15px;
                padding: 15px;
            }
            QPushButton:hover {
                background-color: #c0392b;
            }
        """)
        layout.addWidget(self.detect_btn)

        # åœæ­¢æŒ‰é’®ï¼ˆä»…è§†é¢‘æ¨¡å¼ï¼‰
        self.stop_btn = QPushButton("â¹ åœæ­¢è¯†åˆ«")
        self.stop_btn.clicked.connect(self.stop_detection)
        self.stop_btn.setEnabled(False)
        self.stop_btn.setStyleSheet("""
            QPushButton {
                background-color: #95a5a6;
                font-size: 15px;
                padding: 15px;
            }
            QPushButton:hover {
                background-color: #7f8c8d;
            }
        """)
        layout.addWidget(self.stop_btn)

        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setStyleSheet("""
            QProgressBar {
                border: 2px solid #bdc3c7;
                border-radius: 8px;
                text-align: center;
                height: 25px;
            }
            QProgressBar::chunk {
                background-color: #3498db;
                border-radius: 6px;
            }
        """)
        layout.addWidget(self.progress_bar)

        # ç±»åˆ«è¯´æ˜
        info_group = QGroupBox("ğŸ“‹ è¯†åˆ«ç±»åˆ«")
        info_layout = QVBoxLayout()

        for i, class_name in enumerate(self.class_names):
            color = ["#27ae60", "#e67e22", "#e74c3c", "#9b59b6"][i]
            # ä½¿ç”¨ä¸­æ–‡åç§°
            cn_name = CLASS_NAMES_CN.get(class_name, class_name)
            label = QLabel(f"â— {cn_name}")
            label.setStyleSheet(f"color: {color}; font-size: 13px; padding: 5px;")
            info_layout.addWidget(label)

        info_group.setLayout(info_layout)
        layout.addWidget(info_group)

        # ç—…å®³æ²»ç†è¯´æ˜
        treatment_group = QGroupBox("ğŸ’Š ç—…å®³æ²»ç†æ–¹å¼")
        treatment_layout = QVBoxLayout()

        self.treatment_text = QTextEdit()
        self.treatment_text.setReadOnly(True)
        self.treatment_text.setMaximumHeight(250)
        self.treatment_text.setStyleSheet("""
            QTextEdit {
                background-color: #fefefe;
                border: 1px solid #d5d8dc;
                border-radius: 6px;
                padding: 10px;
                font-size: 12px;
                line-height: 1.6;
                color: #2c3e50;
            }
        """)
        self.treatment_text.setHtml("""
            <div style='color: #7f8c8d; text-align: center; padding: 20px;'>
                <p>ğŸ‘† è¯·å…ˆè¿›è¡Œè¯†åˆ«</p>
                <p style='font-size: 11px;'>è¯†åˆ«åå°†æ˜¾ç¤ºå¯¹åº”çš„æ²»ç†æ–¹å¼</p>
            </div>
        """)

        treatment_layout.addWidget(self.treatment_text)
        treatment_group.setLayout(treatment_layout)
        layout.addWidget(treatment_group)

        # çŠ¶æ€ä¿¡æ¯
        self.status_label = QLabel("ğŸ“Š çŠ¶æ€: å°±ç»ª")
        self.status_label.setStyleSheet("""
            background-color: #ecf0f1;
            padding: 10px;
            border-radius: 8px;
            font-size: 13px;
        """)
        layout.addWidget(self.status_label)

        layout.addStretch()
        return panel

    def create_right_panel(self):
        """åˆ›å»ºå³ä¾§æ˜¾ç¤ºåŒºåŸŸ"""
        panel = QFrame()
        panel.setStyleSheet("""
            QFrame {
                background-color: white;
                border-radius: 12px;
                padding: 15px;
            }
        """)
        layout = QVBoxLayout(panel)
        layout.setSpacing(15)

        # æ ‡é¢˜
        title = QLabel("ğŸ–¼ï¸ æ˜¾ç¤ºåŒºåŸŸ")
        title.setFont(QFont("Arial", 18, QFont.Bold))
        title.setStyleSheet("color: #2c3e50; padding: 10px;")
        layout.addWidget(title)

        # å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setStyleSheet("""
            QLabel {
                background-color: #ecf0f1;
                border: 3px dashed #bdc3c7;
                border-radius: 12px;
                min-height: 450px;
                font-size: 16px;
                color: #7f8c8d;
            }
        """)
        self.image_label.setText("ğŸ“¸ è¯·é€‰æ‹©å›¾ç‰‡æˆ–è§†é¢‘æ–‡ä»¶")
        layout.addWidget(self.image_label, 3)

        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        result_group = QGroupBox("ğŸ”¬ è¯†åˆ«ç»“æœ")
        result_layout = QVBoxLayout()

        self.result_text = QTextEdit()
        self.result_text.setReadOnly(True)
        self.result_text.setMaximumHeight(200)
        self.result_text.setStyleSheet("""
            QTextEdit {
                font-family: 'Consolas', 'Monaco', monospace;
                font-size: 13px;
                line-height: 1.5;
            }
        """)
        result_layout.addWidget(self.result_text)

        result_group.setLayout(result_layout)
        layout.addWidget(result_group, 1)

        return panel

    def load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆæ”¯æŒONNXå’ŒYOLOæ ¼å¼ï¼‰"""
        try:
            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ­£åœ¨åŠ è½½æ¨¡å‹...")
            self.progress_bar.setValue(50)

            # ä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹è·¯å¾„
            model_path = MODEL_PATH

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(model_path).exists():
                self.status_label.setText("ğŸ“Š çŠ¶æ€: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ° âœ—")
                self.add_result_text(f"âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}", "#e74c3c")
                self.add_result_text("è¯·å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶æ”¾åœ¨ç¨‹åºç›®å½•ä¸‹", "#e67e22")
                return

            # åˆ¤æ–­æ¨¡å‹ç±»å‹
            if model_path.endswith('.onnx'):
                # åŠ è½½ONNXæ¨¡å‹
                if not ONNX_AVAILABLE:
                    self.status_label.setText("ğŸ“Š çŠ¶æ€: ONNX Runtimeæœªå®‰è£… âœ—")
                    self.add_result_text("âŒ è¯·å…ˆå®‰è£… onnxruntime: pip install onnxruntime", "#e74c3c")
                    return

                self.add_result_text("ğŸ”„ æ­£åœ¨åŠ è½½ONNXæ¨¡å‹...", "#3498db")
                self.model = ONNXModel(model_path, self.class_names)
                self.is_onnx = True
                self.status_label.setText("ğŸ“Š çŠ¶æ€: ONNXæ¨¡å‹åŠ è½½æˆåŠŸ âœ“")
                self.progress_bar.setValue(100)
                self.add_result_text("âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸï¼", "#27ae60")
                self.add_result_text(f"ğŸ“ è¾“å…¥å°ºå¯¸: {self.model.img_size}x{self.model.img_size}", "#3498db")
            else:
                # åŠ è½½Ultralytics YOLOæ¨¡å‹
                if not ULTRALYTICS_AVAILABLE:
                    self.status_label.setText("ğŸ“Š çŠ¶æ€: Ultralyticsæœªå®‰è£… âœ—")
                    self.add_result_text("âŒ è¯·å…ˆå®‰è£… ultralytics: pip install ultralytics", "#e74c3c")
                    return

                self.add_result_text("ğŸ”„ æ­£åœ¨åŠ è½½YOLOæ¨¡å‹...", "#3498db")
                self.model = YOLO(model_path)
                self.is_onnx = False
                self.status_label.setText("ğŸ“Š çŠ¶æ€: YOLOæ¨¡å‹åŠ è½½æˆåŠŸ âœ“")
                self.progress_bar.setValue(100)
                self.add_result_text("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸï¼", "#27ae60")

        except Exception as e:
            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ¨¡å‹åŠ è½½å¤±è´¥ âœ—")
            self.add_result_text(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}", "#e74c3c")
            import traceback
            self.add_result_text(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}", "#95a5a6")

    def on_mode_changed(self):
        """è¯†åˆ«æ¨¡å¼åˆ‡æ¢"""
        if self.camera_radio.isChecked():
            # æ‘„åƒå¤´æ¨¡å¼ï¼Œéšè—æ–‡ä»¶é€‰æ‹©æŒ‰é’®
            self.select_btn.setEnabled(False)
            self.select_btn.setText("ğŸ“¹ æ‘„åƒå¤´æ¨¡å¼")
            self.detect_btn.setEnabled(True)
            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ‘„åƒå¤´æ¨¡å¼å°±ç»ª")
        else:
            # æ–‡ä»¶æ¨¡å¼ï¼Œæ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©æŒ‰é’®
            self.select_btn.setEnabled(True)
            if self.image_radio.isChecked():
                self.select_btn.setText("ğŸ“ é€‰æ‹©å›¾ç‰‡")
            else:
                self.select_btn.setText("ğŸ“ é€‰æ‹©è§†é¢‘")
            self.detect_btn.setEnabled(False)
            self.status_label.setText("ğŸ“Š çŠ¶æ€: è¯·é€‰æ‹©æ–‡ä»¶")

    def select_file(self):
        """é€‰æ‹©æ–‡ä»¶"""
        if self.camera_radio.isChecked():
            # æ‘„åƒå¤´æ¨¡å¼ä¸éœ€è¦é€‰æ‹©æ–‡ä»¶
            return

        if self.image_radio.isChecked():
            file_path, _ = QFileDialog.getOpenFileName(
                self, "é€‰æ‹©å›¾ç‰‡", "",
                IMAGE_FORMATS
            )
        else:
            file_path, _ = QFileDialog.getOpenFileName(
                self, "é€‰æ‹©è§†é¢‘", "",
                VIDEO_FORMATS
            )

        if file_path:
            self.current_file = file_path
            self.detect_btn.setEnabled(True)
            self.status_label.setText(f"ğŸ“Š çŠ¶æ€: å·²é€‰æ‹©æ–‡ä»¶")
            self.add_result_text(f"ğŸ“ å·²é€‰æ‹©: {Path(file_path).name}", "#3498db")

            # å¦‚æœæ˜¯å›¾ç‰‡ï¼Œæ˜¾ç¤ºé¢„è§ˆ
            if self.image_radio.isChecked():
                self.display_image(file_path)

    def display_image(self, image_path):
        """æ˜¾ç¤ºå›¾ç‰‡"""
        pixmap = QPixmap(image_path)
        scaled_pixmap = pixmap.scaled(
            self.image_label.size(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

    def display_frame(self, frame):
        """æ˜¾ç¤ºè§†é¢‘å¸§"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_frame.shape
        bytes_per_line = ch * w
        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(qt_image)
        scaled_pixmap = pixmap.scaled(
            self.image_label.size(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

    def start_detection(self):
        """å¼€å§‹è¯†åˆ«"""
        if not self.model:
            self.add_result_text("âŒ æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«", "#e74c3c")
            return

        self.result_text.clear()
        self.progress_bar.setValue(0)

        if self.image_radio.isChecked():
            self.detect_image()
        elif self.video_radio.isChecked():
            self.detect_video()
        else:  # æ‘„åƒå¤´æ¨¡å¼
            self.detect_camera()

    def detect_image(self):
        """å›¾ç‰‡è¯†åˆ«"""
        try:
            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ­£åœ¨è¯†åˆ«...")
            self.progress_bar.setValue(30)
            self.add_result_text("ğŸ” å¼€å§‹å›¾ç‰‡è¯†åˆ«...", "#3498db")

            # è¯»å–å›¾åƒ
            image = cv2.imread(self.current_file)

            if self.is_onnx:
                # ONNXæ¨¡å‹æ¨ç†
                self.add_result_text("ğŸ”„ ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œæ¨ç†...", "#3498db")
                boxes = self.model.predict(image, conf_threshold=CONFIDENCE_THRESHOLD)

                self.progress_bar.setValue(70)

                # ç»˜åˆ¶ç»“æœ
                annotated_img = self.model.draw_boxes(image, boxes)
                self.display_frame(annotated_img)

                # è§£æç»“æœ
                if len(boxes) > 0:
                    self.add_result_text("\nâœ… æ£€æµ‹ç»“æœ:", "#27ae60")
                    detected_classes = set()
                    for i, box in enumerate(boxes):
                        cls_id = int(box[5])
                        conf = float(box[4])
                        class_name = self.class_names[cls_id]
                        cn_name = CLASS_NAMES_CN.get(class_name, class_name)
                        detected_classes.add(class_name)

                        color = CLASS_COLORS.get(class_name, "#3498db")
                        self.add_result_text(
                            f"  {i+1}. {cn_name} - ç½®ä¿¡åº¦: {conf:.2%}",
                            color
                        )

                    # æ›´æ–°æ²»ç†æ–¹å¼æ˜¾ç¤º
                    self.update_treatment_info(detected_classes)
                else:
                    self.add_result_text("â„¹ï¸ æœªæ£€æµ‹åˆ°ç—…è™«å®³", "#95a5a6")
                    self.clear_treatment_info()
            else:
                # Ultralytics YOLOæ¨ç†
                self.add_result_text("ğŸ”„ ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ¨ç†...", "#3498db")
                results = self.model.predict(source=self.current_file, conf=CONFIDENCE_THRESHOLD, verbose=False)

                self.progress_bar.setValue(70)

                # æ˜¾ç¤ºç»“æœå›¾ç‰‡
                annotated_img = results[0].plot()
                self.display_frame(annotated_img)

                # è§£æç»“æœ
                if len(results[0].boxes) > 0:
                    self.add_result_text("\nâœ… æ£€æµ‹ç»“æœ:", "#27ae60")
                    detected_classes = set()
                    for i, box in enumerate(results[0].boxes):
                        cls_id = int(box.cls[0])
                        conf = float(box.conf[0])
                        class_name = results[0].names[cls_id]
                        cn_name = CLASS_NAMES_CN.get(class_name, class_name)
                        detected_classes.add(class_name)

                        color = CLASS_COLORS.get(class_name, "#3498db")
                        self.add_result_text(
                            f"  {i+1}. {cn_name} - ç½®ä¿¡åº¦: {conf:.2%}",
                            color
                        )

                    # æ›´æ–°æ²»ç†æ–¹å¼æ˜¾ç¤º
                    self.update_treatment_info(detected_classes)
                else:
                    self.add_result_text("â„¹ï¸ æœªæ£€æµ‹åˆ°ç—…è™«å®³", "#95a5a6")
                    self.clear_treatment_info()

            self.progress_bar.setValue(100)
            self.status_label.setText("ğŸ“Š çŠ¶æ€: è¯†åˆ«å®Œæˆ âœ“")

        except Exception as e:
            self.add_result_text(f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}", "#e74c3c")
            self.status_label.setText("ğŸ“Š çŠ¶æ€: è¯†åˆ«å¤±è´¥ âœ—")
            import traceback
            self.add_result_text(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}", "#95a5a6")

    def detect_video(self):
        """è§†é¢‘è¯†åˆ«"""
        try:
            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ­£åœ¨è¯†åˆ«è§†é¢‘...")
            self.add_result_text("ğŸ¥ å¼€å§‹è§†é¢‘è¯†åˆ«...", "#3498db")

            if self.is_onnx:
                self.add_result_text("ğŸ”„ ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œè§†é¢‘æ¨ç†...", "#3498db")
            else:
                self.add_result_text("ğŸ”„ ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œè§†é¢‘æ¨ç†...", "#3498db")

            # ç¦ç”¨æŒ‰é’®
            self.detect_btn.setEnabled(False)
            self.select_btn.setEnabled(False)
            self.stop_btn.setEnabled(True)

            # åˆ›å»ºå¹¶å¯åŠ¨è§†é¢‘çº¿ç¨‹
            self.video_thread = VideoThread(self.current_file, self.model, self.is_onnx)
            self.video_thread.change_pixmap_signal.connect(self.display_frame)
            self.video_thread.result_signal.connect(self.update_video_result)
            self.video_thread.finished_signal.connect(self.video_finished)
            self.video_thread.start()

        except Exception as e:
            self.add_result_text(f"âŒ è§†é¢‘è¯†åˆ«å¤±è´¥: {str(e)}", "#e74c3c")
            self.status_label.setText("ğŸ“Š çŠ¶æ€: è¯†åˆ«å¤±è´¥ âœ—")
            self.detect_btn.setEnabled(True)
            self.select_btn.setEnabled(True)
            self.stop_btn.setEnabled(False)
            import traceback
            self.add_result_text(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}", "#95a5a6")

    def detect_camera(self):
        """æ‘„åƒå¤´è¯†åˆ«"""
        try:
            # æ£€æŸ¥ WiFi è¿æ¥
            self.add_result_text("ğŸ” æ­£åœ¨æ£€æŸ¥ WiFi è¿æ¥...", "#3498db")
            is_connected, current_ssid, error = check_wifi_connection(self.camera_wifi_ssid)

            if error:
                self.add_result_text(f"âŒ WiFi æ£€æŸ¥å¤±è´¥: {error}", "#e74c3c")
                QMessageBox.warning(self, "WiFi æ£€æŸ¥å¤±è´¥", f"æ— æ³•æ£€æŸ¥ WiFi è¿æ¥çŠ¶æ€\n\né”™è¯¯: {error}")
                return

            if not is_connected:
                self.add_result_text(f"âš ï¸  æœªè¿æ¥åˆ°æ‘„åƒå¤´ WiFi", "#e67e22")
                self.add_result_text(f"   å½“å‰è¿æ¥: {current_ssid}", "#95a5a6")
                self.add_result_text(f"   éœ€è¦è¿æ¥: {self.camera_wifi_ssid}", "#95a5a6")

                reply = QMessageBox.question(
                    self,
                    "WiFi æœªè¿æ¥",
                    f"å½“å‰æœªè¿æ¥åˆ°æ‘„åƒå¤´ WiFi\n\n"
                    f"å½“å‰è¿æ¥: {current_ssid}\n"
                    f"éœ€è¦è¿æ¥: {self.camera_wifi_ssid}\n\n"
                    f"è¯·è¿æ¥åˆ°æ­£ç¡®çš„ WiFi åé‡è¯•ã€‚\n\n"
                    f"æ˜¯å¦ç»§ç»­å°è¯•è¿æ¥æ‘„åƒå¤´ï¼Ÿ",
                    QMessageBox.Yes | QMessageBox.No
                )

                if reply == QMessageBox.No:
                    return
            else:
                self.add_result_text(f"âœ… å·²è¿æ¥åˆ°æ‘„åƒå¤´ WiFi: {self.camera_wifi_ssid}", "#27ae60")

            # å¼€å§‹æ‘„åƒå¤´è¯†åˆ«
            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ­£åœ¨è¿æ¥æ‘„åƒå¤´...")
            self.add_result_text("ğŸ“¹ å¼€å§‹æ‘„åƒå¤´è¯†åˆ«...", "#3498db")
            self.add_result_text(f"ğŸ“¡ æ‘„åƒå¤´åœ°å€: {self.camera_url}", "#95a5a6")

            if self.is_onnx:
                self.add_result_text("ğŸ”„ ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œå®æ—¶æ¨ç†...", "#3498db")
            else:
                self.add_result_text("ğŸ”„ ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œå®æ—¶æ¨ç†...", "#3498db")

            # ç¦ç”¨æŒ‰é’®
            self.detect_btn.setEnabled(False)
            self.select_btn.setEnabled(False)
            self.stop_btn.setEnabled(True)

            # åˆ›å»ºå¹¶å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹
            self.camera_thread = CameraThread(self.camera_url, self.model, self.is_onnx)
            self.camera_thread.change_pixmap_signal.connect(self.display_frame)
            self.camera_thread.result_signal.connect(self.update_video_result)
            self.camera_thread.error_signal.connect(self.camera_error)
            self.camera_thread.start()

            self.status_label.setText("ğŸ“Š çŠ¶æ€: æ‘„åƒå¤´è¯†åˆ«ä¸­...")
            self.add_result_text("âœ… æ‘„åƒå¤´è¿æ¥æˆåŠŸï¼Œå¼€å§‹å®æ—¶è¯†åˆ«", "#27ae60")

        except Exception as e:
            self.add_result_text(f"âŒ æ‘„åƒå¤´è¯†åˆ«å¤±è´¥: {str(e)}", "#e74c3c")
            self.status_label.setText("ğŸ“Š çŠ¶æ€: è¯†åˆ«å¤±è´¥ âœ—")
            self.detect_btn.setEnabled(True)
            self.select_btn.setEnabled(False)
            self.stop_btn.setEnabled(False)
            import traceback
            self.add_result_text(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}", "#95a5a6")

    def camera_error(self, error_msg):
        """æ‘„åƒå¤´é”™è¯¯å¤„ç†"""
        self.add_result_text(f"âŒ æ‘„åƒå¤´é”™è¯¯: {error_msg}", "#e74c3c")
        QMessageBox.critical(self, "æ‘„åƒå¤´é”™è¯¯", error_msg)
        self.stop_detection()

    def update_video_result(self, class_name, confidence):
        """æ›´æ–°è§†é¢‘è¯†åˆ«ç»“æœ"""
        cn_name = CLASS_NAMES_CN.get(class_name, class_name)
        color = CLASS_COLORS.get(class_name, "#3498db")
        self.add_result_text(f"ğŸ” æ£€æµ‹åˆ°: {cn_name} (ç½®ä¿¡åº¦: {confidence:.2%})", color)

        # æ›´æ–°æ²»ç†æ–¹å¼æ˜¾ç¤ºï¼ˆåªæ˜¾ç¤ºæœ€æ–°æ£€æµ‹åˆ°çš„ç±»åˆ«ï¼‰
        self.update_treatment_info({class_name})

    def stop_detection(self):
        """åœæ­¢è§†é¢‘/æ‘„åƒå¤´è¯†åˆ«"""
        if self.video_thread:
            self.video_thread.stop()
            self.video_thread = None
            self.add_result_text("â¹ å·²åœæ­¢è§†é¢‘è¯†åˆ«", "#95a5a6")

        if self.camera_thread:
            self.camera_thread.stop()
            self.camera_thread = None
            self.add_result_text("â¹ å·²åœæ­¢æ‘„åƒå¤´è¯†åˆ«", "#95a5a6")

        # æ¢å¤æŒ‰é’®çŠ¶æ€
        self.detect_btn.setEnabled(True)
        self.select_btn.setEnabled(not self.camera_radio.isChecked())
        self.stop_btn.setEnabled(False)
        self.status_label.setText("ğŸ“Š çŠ¶æ€: å·²åœæ­¢")

    def video_finished(self):
        """è§†é¢‘è¯†åˆ«å®Œæˆ"""
        self.status_label.setText("ğŸ“Š çŠ¶æ€: è§†é¢‘è¯†åˆ«å®Œæˆ âœ“")
        self.detect_btn.setEnabled(True)
        self.select_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.progress_bar.setValue(100)
        self.add_result_text("âœ… è§†é¢‘è¯†åˆ«å®Œæˆ", "#27ae60")

    def update_treatment_info(self, detected_classes):
        """æ›´æ–°æ²»ç†æ–¹å¼æ˜¾ç¤º"""
        if not detected_classes:
            self.clear_treatment_info()
            return

        html_content = ""
        for class_name in detected_classes:
            if class_name in DISEASE_TREATMENTS:
                treatment = DISEASE_TREATMENTS[class_name]
                color = CLASS_COLORS.get(class_name, "#3498db")

                html_content += f"""
                <div style='margin-bottom: 15px; padding: 10px; background-color: #f8f9fa; border-left: 4px solid {color}; border-radius: 4px;'>
                    <h3 style='color: {color}; margin: 0 0 8px 0; font-size: 14px;'>
                        â— {treatment['name']}
                    </h3>
                    <p style='margin: 5px 0; color: #7f8c8d; font-size: 11px;'>
                        {treatment['description']}
                    </p>
                    <div style='margin-top: 8px; padding: 8px; background-color: white; border-radius: 3px;'>
                        <p style='margin: 0; color: #2c3e50; font-size: 11px; white-space: pre-line;'>
                            {treatment['treatment']}
                        </p>
                    </div>
                </div>
                """

        if html_content:
            self.treatment_text.setHtml(html_content)
        else:
            self.clear_treatment_info()

    def clear_treatment_info(self):
        """æ¸…ç©ºæ²»ç†æ–¹å¼æ˜¾ç¤º"""
        self.treatment_text.setHtml("""
            <div style='color: #7f8c8d; text-align: center; padding: 20px;'>
                <p>ğŸ‘† è¯·å…ˆè¿›è¡Œè¯†åˆ«</p>
                <p style='font-size: 11px;'>è¯†åˆ«åå°†æ˜¾ç¤ºå¯¹åº”çš„æ²»ç†æ–¹å¼</p>
            </div>
        """)

    def add_result_text(self, text, color="#2c3e50"):
        """æ·»åŠ ç»“æœæ–‡æœ¬"""
        self.result_text.append(f'<span style="color: {color};">{text}</span>')
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        self.result_text.verticalScrollBar().setValue(
            self.result_text.verticalScrollBar().maximum()
        )

    def closeEvent(self, event):
        """å…³é—­çª—å£æ—¶åœæ­¢è§†é¢‘çº¿ç¨‹"""
        if self.video_thread and self.video_thread.isRunning():
            self.video_thread.stop()
        event.accept()


def main():
    app = QApplication(sys.argv)

    # è®¾ç½®åº”ç”¨ç¨‹åºå­—ä½“
    font = QFont("Microsoft YaHei", 10)
    app.setFont(font)

    window = DiseaseDetectionUI()
    window.show()
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()

